

# 程序是怎样跑起来的？

[TOC] 



## 虚拟内存出现之前

先来看看在操作系统还没有支持分段以及分页，以及虚拟内存技术的时候，程序是如何运行起来的，我以 C 代码举例，其它编程语言也是类似的。

```c
1. 编写程序
    
int main(){
    // 代码
    
    return 0;
}

2.编译成机器代码(01代码)，这里以伪汇编代码作为展示
 .text
 _entry: //入口地址
    call _main
    call _exit
 _main:
   ...
       
 .text
 	_entry: //入口地址
      call 40
      call 50
 _main:  // _main 偏移是 40
   ...   
```

 -------------------------------------------------------------------------
 函数和全局变量(静态变量)，我们称之为符号，在链接的时候才会给符号分配内存地址。
 ------------------------------------------------------------------------
 
3.将程序载入内存

![image-01](https://i.postimg.cc/G23QqnNv/01.png)

上面所说的程序的运行方式其实属于单一连续内存分配方式，这种方式允许物理内存同一时刻只运行一个程序， 类似于单片机。
单一连续内存分配方式的缺点：
1. 只能运行一个程序
2. 内存的使用率不高(当程序的大小远小于物理内存空间时)


我们希望计算机可以运行更多的程序，从而有效的利用计算机的硬件资源(比如物理内存..)，那如何让计算机可以运行更多的程序呢？


很容易想到的一个方法是：让操作系统为每个程序分配它们各自所需的物理内存。

**如图所示：**


![image-02](https://i.postimg.cc/j58h1k0m/02.png)



上图展示了为一个进程分配物理内存的情况，如果是多个进程同时运行的话，操作系统就必须为每个进程分配物理内存，而这样的话，每个进程就分别拥有自己的内存空间，而这个内存空间的起始地址，也叫基地址。这样操作系统就可以根据进程各自的基地址将程序加载至对应的物理内存中。

但是，这样也是存在问题的？

cpu 执行的第一条指令应该是 call 1040 ，而不是call 40，因为40属于逻辑地址(相对地址)，必须进行重定位形成物理地址，即：用段的基址+段内偏移(1000+40) => 物理地址，这个重定位过程一般都是由硬件( CPU )来完成的。



上面所说的内存分配方式叫做非固定分区内存的管理方式。那什么是非固定分区的内存管理方式呢？说的简单一点就是你的程序有多大，操作系统就给你分配多大的内存，但是程序所使用的物理内存可能会发生改变(比如: 程序因为阻塞而被换出内存，下次再换入的时候物理内存就有可能发生改变)

那非固定分区的内存管理方式有什么缺点呢？
一个最主要的缺点就是会产生外碎片。

大家需要明白的一点就是，非固定分区的内存管理方式和我接下来说的分段的思想其实是一样的。

**总结一下：多个程序要想同时运行起来，得有以下几个步骤：**

- 操作系统得创建进程，即创建 PCB

- 在物理内存找空闲内存，将这个空闲内存的起始地址(程序的基地址)保存在 各自进程的 PCB 中

- 将编译好的二进制程序存放在上面的空闲内存中

- cpu 不断的进行取指-执行，取指-执行。（在取指的时候，cpu先拿到的是逻辑地址，也就是相对地址，必须要进行运行时的重定位，即：cpu从基址寄存器中拿到空闲内存的起始地址(基地址)，要通过运算得到物理地址，才能进行真正的访存。

  

**注意：** 上述的例子，给程序分配的都是一段连续的内存区域，这种内存管理方式我们也称连续内存分配方式。



## 内存不够用怎么办？

我们的期望是操作系统上能够运行更多的程序，但是早期的操作系统受到硬件资源的限制(比如：物理内存比较小而且昂贵，不支持有效的内存管理机制)，这就限制了操作系统不能同时运行更多的程序，当时出现了覆盖和交换技术，有效地解决了内存不够的情况。 

###  覆盖

1. 把某一个程序按照其自身逻辑结构，划分为若干个功能上相对独立的程序模块，那些不会同时执行的模块共享同一块内存区域，按时间先后来运行。程序员也需要编写一个小的程序来管理这些模块何时应该驻留内存而合适应该被替换掉。这个小的程序就是所谓的**覆盖管理器(Overlay Manager)**

2. 覆盖的简单图示：

   a：假设可用的物理内存只有1536k, 而该应用程序总大小为 1024K + 512K + 256K = 1792K,并且 main 函数和模块 B 和模块 C存在调用关系，即：main 函数里调用了 函数 B 和 函数 C，而 B 和 C 之间不存在函数调用关系。

   b: 而一般情况下，main 函数的代码是常驻内存的，这样模块 B 和 C 就可以共享剩下的 512k ，有效的解决了物理内存不足的问题。

   c: 覆盖是针对单个程序来说的。而且程序中所有的函数的调用关系不能形成一个调用链，即：main -> func1 -> func2 ,如果形成一个调用链,是没有办法节省物理内存的。可执行程序有多大，物理内存就必须有多大。
   
   

![image-03](https://i.postimg.cc/vTktYgmv/03.png)

   
3. 覆盖的缺点：

   - 由程序员来把一个大的程序划分为若干个小的功能模块，并确定各个模块之间的覆盖关系，费时费力，增加了编程的难度。

   - 覆盖模块从磁盘装入内存，实际上是以时间延长来换取空间的节省。

     

### 交换

1. 将暂时不能运行的程序换出到磁盘，将要运行的程序换入到内存，交换是以整个程序为单位的。

2. 简单图示：

   
![image-04](https://i.postimg.cc/rsK92Cqm/04.png)



### 分段和分页的引入

首先说明一下，大学我们学习的操作系统，都是讲的是 Intel x86 CPU 架构下的分段式内存管理和分页式内存管理，当然我讲的也是这种架构下的。
分段和分页的引入其实就是为了更加高效的使用内存。

#### 简单的内存分配策略

在谈分段和分页之前，我们先来看一种简单的内存分配策略，其实就是上面我提到过的非固定分区的内存管理方式。

假设我们的计算机的物理内存100MB的物理内存，程序 A 运行需要 10MB，程序 B 运行需要80MB，程序 C 运行需要 20MB，如果我们要同时运行程序 A 和 B,  那么我们可以想到一个最简单的内存分配方式： 将物理内存的前 10 M分配给程序A，10M ~ 90M分配给程序 B,这样就能够实现程序 A 和程序 B同时运行。但这种简单的内存分配策略问题很多，比如下面的这几个：

- **地址空间不隔离**：程序所使用的内存空间都不是相互隔离的。恶意的程序可以很容易的改写其它程序的内存数据，这会使得其它程序崩溃。
- **内存使用效率低：** 
  1. 换入和换出还是以整个程序为单位，还是以时间延长来换取空间的节省，换入换出的工作是由操作系统来完成的，程序员不需要关心。
  2. 正是因为装载程序至物理内存是以整个程序为单位的，这就造成了给每个程序分配物理内存的时候，都是分配一个连续的物理内存区域，而这种方式有明显的缺点，即：对内存的使用效率比较低，容易产生内存碎片(外碎片)。


![image-05](https://i.postimg.cc/sfNc98JZ/05.png)



随着计算机硬件( CPU )的发展，使得硬件支持了分段和分页


#### 分段

我们先来思考一下为什么要引入分段呢？

因为早期的8086处理器寄存器宽度只有16位，16位的寄存器只能进行 64 KB 的寻址，而 8086 有 20 根地址线，按照地址线来计算可以进行 1 MB 的寻址，16 位宽度的寄存器是显然不能满足需求的，为了解决这个问题，于是就想到了用分段(段基址 : 段内偏移)的方式来扩展寻址空间。除此之外分段还解决了上述连续内存分配的缺点。

这里我还要简单说下操作系统的 2 种运行模式: 实模式和保护模式
在实模式下，段寄存器直接存放的就是段基址，并没有存放段界限等信息，这就导致了不安全，程序的某个段可以非法访问另外程序的地址。

随着硬件 CPU 的发展 ，为了满足不断增长的内存需求，研发出了 32位 的寄存器，还顺带着搞出了一个保护模式。

在保护模式下，很重要的一点就是段寄存器不是直接存放段基址了，而是存放着段选择子，段选择子不仅包含着段基址还包含着段界限等重要信息。也解决了实模式的不安全的问题。



**而我这里讲的分段其实就是 32 位系统的保护模式的分段：**


- 引入了分段机制之后，用户程序使用的逻辑地址分为两部分，一部分用来表示段号， 另一部分表示段内偏移。

- 分段的简单图示：


![image-06](https://i.postimg.cc/Kv359N9p/06.png)



- 下面我将用一个图来说明硬件是如何支持分段的？


![image-07](https://i.postimg.cc/4xzQG3Rz/07.png)




接下来我们来谈下分段机制是如何解决连续内存管理的那几个缺点的？

**分段的优点：**

- 首先是解决了各个程序地址空间不隔离的问题，大家可以先想想是怎么解决的？

因为 CPU 中的段寄存器中的段选择子不仅存放着段基址，而且也存放着段界限的信息，这就确保了程序中的某个段不会非法访问其它程序的段。

- 内存使用效率相比之前的有了很大的改善，程序是以段为单位进行换入换出的，而不是以整个程序为单位。

因为引入了逻辑地址空间，通过段表来建立逻辑地址空间和物理地址空间的映射，对于用户程序，只需要在逻辑地址空间进行编码即可。


**分段的缺点：**

1. 比较浪费内存，容易产生外部碎片，但是相比连续内存分配方式确实好了很多，因为段相比程序来说所占内存空间确实小了。
2. 程序在换入和换出内存都是以段为单位的，是以时间换空间的。但段还是比较大，在换入和换出的时候时间就会稍微久些，给用户的感受就是程序会卡顿。


Intel x86 CPU 架构下的分段式内存管理和分页式内存管理

#### 分页

引入了分段，为什么还要引入分页呢？

其实就是为了更加高效地利用主存，解决分段的缺点。

分页的基本方法是把逻辑地址空间等分成固定大小的页，每一页的大小由硬件决定。把物理内存空间分成与页大小相等的若干个存储块，称为页框。

在 32 位系统下，页和页框的大小一般是 4k Bytes.

- 引入了分页机制之后，程序员使用的逻辑地址分为两部分，一部分用来表示页号， 另一部分表示页内偏移，而物理地址分成帧号和帧内偏移。

- 硬件是怎么支持分页的？

  

![image-08](https://i.postimg.cc/cLqBPn2x/08.png)

  

- 分页的优点：

  其实分段的优点，分页都具备，而且分页改善了分段的缺点，没有了外碎片。

- 分页的缺点：

  会产生内碎片，这个是不可避免的。





#### 段页式存储管理

段页式存储管理其实就是将分段和分页的思想结合起来的一种管理内存的方式。综合了分段和分页的优点。



**地址结构：**


![image-09](https://i.postimg.cc/VNmBkcz2/09.png)


1. 段号的位数决定了每个进程最多可以分几个段

2. 段内页号位数决定了每个段最大有多少个页

3. 页内偏移量决定了页面大小、内存块(页框)大小是多少



- 硬件是怎么支持段页式存储的？


![image-10](https://i.postimg.cc/sX0pmQ5R/10.png)


段页式内存管理的方式，逻辑地址到物理地址的转换会经过以下几个过程：

逻辑地址 ---> 虚拟地址 ---> 物理地址


**细节说明**

​ 首先 CPU 访问的是逻辑地址0x0040，它首先会根据段号去查段表，得到虚拟地址 0x001040,然后根据虚拟地址的页号去查页表，如果该项的标记位为 1，则 CPU 就可以直接得到物理地址，然后访存， 但如果该项的标记位为 0 ，则会发生缺页中断，操作系统将从物理内存分配一个物理页，然后将该“缺页”从磁盘加载至物理内存中，最后再设置该缺页的虚拟页与物理页的映射关系 ，然后 CPU 会重新访问这个虚拟地址，再次查页表得到物理内存地址，从而进行访存。



**流程图展示**：


![image-11](https://i.postimg.cc/CK7CZ615/11.png)





####  Intel x86 CPU 架构下 Linux 操作系统实际采用的内存管理方式 

先说结论：Linux 操作系统实际采用的是**分段+分页相结合的内存管理方式** ，但实际上操作系统将段给屏蔽了，(如何屏蔽？下面讲)

我以 Linux 32 位操作系统为例，Linux 内核将各个段的基地址设置为 0x00000000，即，进程的代码段，数据段等其它段都是从 0x00000000 开始偏移的，也就是说段内偏移的最大值就是 4G ，与 32 位的操作系统的进程虚拟地址空间为 4G 正好符合。那么, CPU 访问的地址就直接是虚拟地址了 。



分段和分页机制上面已经提到过了，那什么是虚拟内存技术呢？

**下面是我摘取的深入理解计算机系统书上的关于虚拟内存的官方定义：**

为了更加有效的管理物理内存并且少出错，现代操作系统提供了一种对主存的抽象概念，叫做虚拟内存。虚拟内存是**硬件异常、硬件地址翻译、主存、磁盘文件和内核软件**的完美交互，它为每个进程提供了一个大的，一致的和私有的地址空间。不知道大家有没有发现，我上面画的分页机制的流程图的过程，即：CPU 直接访问虚拟地址，到最后的访存，这个过程必须得操作系统支持虚拟内存技术才可以。

通过一个很清晰的机制，虚拟内存提供了三个重要的能力：

1. 它将主存(物理内存)看成是一个存储在磁盘上的地址空间的高速缓存，在主存只保留活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。
2. 它为每个进程提供了一致的地址空间，从而简化了内存管理。
3. 它保护了每个进程的地址空间不被其它进程破坏。



如果大家确实把上面我提到的分段，分页机制搞明白，理解虚拟内存应该是比较容易的。


下面我以一个实际例子来说明应用程序是如何在 Linux 系统上跑起来的？

#### 可执行文件是如何被装载的？

在操作系统支持分段，分页机制以及虚拟内存技术之后，一个程序要想真正跑起来，必须要做以下三件事情:

- 创建一个独立的虚拟地址空间，其实就是分配一个页目录。

- 读取可执行文件头，并且建立虚拟地址空间与可执行文件的映射关系

- 将 CPU 的 PC 寄存器设置为可执行文件的入口地址




**下面我以一个实际的 ELF 文件作为例子，阐述一下可执行文件是怎么被装在至物理内存中，从而跑起来的。**

这里我简单提下 ELF 文件的相关知识。

现在 PC 平台流行的可执行文件格式主要是 Windows 下的 PE 以及 Linux 的 ELF。

- 我们先来看下 ELF 文件的基本结构：


接下来，我简单介绍下 ELF 文件的主要组成：

1. ELF Header ：可执行文件头， 查看命令 :  `readelf -h 可执行文件名`
2. Program Headers ：程序头表 ，查看命令 : `readelf -l 可执行文件名`
3. .text ：代码段，查看命令 : ` objdump -d 可执行文件名 `
4. .data : 数据段
5. Section Header Table ：段表，查看命令 :  `readelf -S 可执行文件名`
6. Symbol Table ：符号表，查看命令： `readelf -s 可执行文件名`


这里我采用的例子是一个开源 Go 项目，程序大小大概几十兆。

首先需要将这个 GO 应用编译成 二进制可执行文件，接下来就是运行这个应用，我们来看下这个应用是怎么运行起来的？

**第一步，就是内核分配的一个页目录，保存的是虚拟页和物理页的映射关系**，其实就是上面所说的页表，只不过它更加特殊些，保存的是多级页表,多级页表下面讲。

**第二步，读取可执行文件头，并且建立虚拟地址空间与可执行文件的映射关系**

我们先来看下该应用的可执行文件头都包含哪些内容？

1.通过 readelf -h 可执行文件名 命令即可查看，示例如下：

```
eg: readelf -h myapp

ELF Header:
Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
Class: ELF64
Data: 2's complement, little endian
Version: 1 (current)
OS/ABI: UNIX - System V
ABI Version: 0
Type: EXEC (Executable file)
Machine: Advanced Micro Devices X86-64
Version: 0x1
Entry point address: 0xd14e80
Start of program headers: 64 (bytes into file)
Start of section headers: 70695328 (bytes into file)
Flags: 0x0
Size of this header: 64 (bytes)
Size of program headers: 56 (bytes)
Number of program headers: 10
Size of section headers: 64 (bytes)
Number of section headers: 45
Section header string table index: 44
```



上述中有一个重要的一项是：`Start of program headers `，含义是**程序头表的起始地址**，操作系统正是通过这个程序头表来建立虚拟地址空间和可执行文件的映射关系的。这里可以引申出来两个问题：

**第一个问题是操作系统怎样建立虚拟地址空间与可执行文件的映射关系？**

**第二个问题是操作系统为何要建立虚拟地址空间与可执行文件的映射关系？**



要想弄清楚以上问题，我们要分析 ELF 文件：

- 先来看下 myapp ELF 文件的各个Section (节头表)，也叫做段表, 这里我只列了几个重要的 Section

  ```
  通过 readelf -S myapp 命令 即可查看:
  There are 45 section headers, starting at offset 0x436b9a0:
  
  Section Headers:
  [Nr] Name 	 Type 	  	Address 	Offset 		Size 		EntSize 	Flags 	Link 	Info 	Align
  [14] .text	 PROGBITS 	00d14e80 	00914e80 	011dc5b2 	00000000 	AX 		0 		0 		32
  [16] .rodata PROGBITS 	01ef1440 	01af1440 	006aac80	00000000 	A 		0 		0 		32
  [27] .data   PROGBITS 	0355b000 	02f5b000 	00020220 	00000000 	WA 		0 		0 		32
  [30] .bss    NOBITS 	0364c060 	0304c044 	00384c0 	0000000 	WA 		0 		0 		32
  [31] .other 						0304c044
  [42] .symtab SYMTAB 	00000000 	0304c0a0 	00485508 	00000018 			43 		68620   8
  
  注意: 上面的 .other 字段名是我任意起的，只是为了说明 .bss 并不占用 ELF 可执行文件的空间(从offset 属性便可以看出)，但是占用虚拟地址空间
  
  重要属性列的含义：
  name : 段名
  Address : 段的虚拟地址
  offset : 段在 ELF 文件中的偏移(距离文件头的偏移)
  size : 段的大小
  ```



- 接下来看下 可执行文件的程序头表的内容，这里只列举 2 个重要的项（2个LOAD 页）

```

执行命令 readelf -l myapp 

Elf file type is EXEC (Executable file)
Entry point 0xd14e80
There are 10 program headers, starting at offset 64

Program Headers:
Type 	Offset 		VirtAddr 	PhysAddr 	FileSiz 	MemSiz 		Flags 	Align
LOAD 	0x00000000 	0x00400000  0x00400000 	0x02f59f48	0x02f59f48 	R E 	0x200000 	---代码段
LOAD 	0x02f5ac08 	0x355ac08 	0x0355ac08 	0x000f143c  0x0013a028  RW 		0x200000 	--- 数据段

Section to Segment mapping:
Segment Sections...

02 .interp .note.ABI-tag .note.go.buildid .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt .init .plt .text .fini .rodata .typelink .itablink .gopclntab .eh_frame_hdr .eh_frame

03 .init_array .fini_array .dynamic .got .data .go.buildinfo .noptrdata .bss .noptrbss

属性列的含义
Offset：该段在 ELF 文件中的偏移
VirtAddr：该段在进程虚拟地址空间的起始地址
FileSiz： 该段在 ELF 文件中所占空间的长度
MemSiz： 该段在进程虚拟地址空间所占用的长度


// 接着来看下 几个重要的段占可执行文件的大小

通过执行 size myapp 命令查看：

text    		data     	bss     	dec     	hex 		filename
49650857                988220   	297944  	50937021        3093cbd 	myapp
```

有两点我们需要知道：

1.在链接器链接的时候，会将相同权限的段合并到一起形成页，然后操作系统在建立可执行文件和虚拟地址空间映射的时候是以页为单位的， Linux 操作系统中页大小为 4K Bytes，合并段的原因就是为了节省内存。

2.操作系统正是通过程序头表建立虚拟地址空间与可执行文件的映射关系的。



-  然后我们再来看下进程的内存映射，这里我只列举了几个重要的段映射。

  **需要说明一点的是程序必须运行起来，才能查看进程的内存映射。**


 1. 进程的内存映射 ：其实就是操作系统建立好的可执行程序与虚拟地址空间的映射关系。
 2. 查看方式 `cat /proc/进程号/maps`


```
执行命令： cat /proc/5248/maps

00400000-0335a000 r-xp 00000000 fc:11 6830208 /mnt1/cmd/sdkSidecar_mq 代码段
0355a000-0355b000 r--p 02f5a000 fc:11 6830208 /mnt1/cmd/sdkSidecar_mq 只读段
0355b000-0364d000 rw-p 02f5b000 fc:11 6830208 /mnt1/cmd/sdkSidecar_mq 数据段
....

```


**第三步：将 CPU 的 PC 寄存器设置为可执行文件的入口地址其实这里说的可执行文件的入口地址。**

其实就是上面可执行文件头里的这一项，`Entry point address` , 这里又引出一个问题？`Entry point address `是main函数的地址吗？这个问题等价于，程序是 从 main 函数开始运行的吗？

其实程序并不是从 main 函数开始运行的 ，操作系统在装载程序之后，首先运行的代码并不是 main 函数，而是执行其它函数代码(被称之为入口函数)，入口函数主要做的其实就是两件事：

- 首先初始化 main 函数执行所需要的环境，包括堆，栈，全局变量等.
- 等 main 函数执行完毕以后，返回到入口函数，入口函数要进行清理工作，包括全局变量析构，堆和栈的销毁等。



**总结：**

下面我画了一个图，这张图只是为让大家能够对 "可执行程序如何装载至内存"有一个整体认识：


![image-12](https://i.postimg.cc/QNwQW7XQ/12.png)





接下来我来谈下上面遗留的问题：

**操作系统为何要建立虚拟地址空间与可执行文件的映射关系？**

原因其实很简单。在谈答案之前，我先大概总结一下上面的三个步骤：

一个应用程序要想运行起来，必须要完成上面的三个步骤，**分配页目录，建立虚拟地址空间和可执行文件的映射，设置 CPU 的 PC寄存器。**

以上三步可以简单理解为内核将进程创建好了，当内核创建好这个进程之后，CPU 访问的第一条指令的地址是 0x00d14e80 (结合上面的图来看)，假设该虚拟页的页号为 0 ，则 CPU 去查页表发现对应的标记位为 0，这时会发生缺页中断，操作系统将从物理内存分配一个物理页，**然后将该“缺页”从磁盘加载至物理内存中**，最后再设置该缺页的虚拟页号与物理页号的映射关系(其实就是在页表增加一条记录) ，然后 CPU 会重新访问这个虚拟地址，再次查页表得到物理内存地址，拿到物理内存地址之后，CPU 才会从物理内存中取指令和数据，从而执行。

上面提到了缺页中断，当 CPU 去查页表发现对应的标记位为 0，这时会发生缺页中断，操作系统将从物理内存分配一个物理页，**然后将该“缺页”从磁盘加载至物理内存中**，但有个问题，操作系统是怎么知道这个虚拟页在可执行文件中的位置？ 答案其实很明显了，正是因为

建立了虚拟地址空间与可执行文件的映射关系，操作系统才能找到 cpu 访问的虚拟地址对应的虚拟页在可执行文件中的偏移，从而将该虚拟页加载至物理页框中(物理内存中)。



**流程图展示**：

与上面的段页式流程图基本一样，只是去掉了逻辑地址和查段表的步骤。


![image-13](https://i.postimg.cc/mkz75LS1/13.png)





**操作系统怎样建立虚拟地址空间与可执行文件的映射关系？**

是通过mmap 建立的。

- 什么是 mmap？

在深入理解计算机系统中，mmap 的定义为：Linux 通过将一个虚拟内存区域与一个磁盘上的对象(object)关联起来(这个对象一般指的是文件)，以初始化这个虚拟内存区域的内容，这个过程称为内存映射。

在谈 mmap 原理之前 ，我们先来看下 32 位的 Linux 操作系统的进程虚拟地址空间分布：



![image-14](https://i.postimg.cc/9MfdytRp/14.png)



- 下面我通过讲一个 mmap 的实际例子，来详细说明 mmap 的原理。

  通过 mmap 函数将 500MB 大小的文件 file 映射至进程的虚拟地址空间，并创建映射关系。

1. 查看文件 `file` 的大小

   ```
   1. [root@localhost test]# ls -lh file
      -rw-r--r--. 1 root root 500M Aug 18 22:42 file
   ```

2. 代码示例

```

int main(){
	int fd = open("file",O_RDWR,775);
	if (fd == -1){
		return -1;
	}
	struct stat file_stat;
	int ret = fstat(fd, &file_stat);	// 获取文件状态
	if (ret == -1) {
		return -1;
	}
	int size = file_stat.st_size;
	char *map=(char*)mmap(NULL,size,PROT_READ|PROT_WRITE,MAP_SHARED,fd,0);
	printf("%s\n",map);
	if (map == NULL){
		printf("mmap err!");
	}
	while(1){
		;
	}
	return 0;
}

```

3. 查看该进程的内存映射

```
[root@localhost test]# cat /proc/2444/maps
00400000-00401000 r-xp 00000000 fd:00 9306708                            /root/test/carl
00600000-00601000 r--p 00000000 fd:00 9306708                            /root/test/carl
00601000-00602000 rw-p 00001000 fd:00 9306708                            /root/test/carl
7fefb9ebc000-7fefd92b8000 rw-s 00000000 fd:00 9267428                    /root/test/file

7fefd92b8000 - 7fefb9ebc000 = 524,271,616  约等于 524268430(file的大小)  单位均是字节
```



4.整体架构图



![image-15](https://i.postimg.cc/yYRFhNdw/15.png)



5. 流程图展示：



![image-16](https://i.postimg.cc/BnG2mGPt/16.png)
   
   



6.细节阐述：

在mmap之后，内核并没有在将文件内容加载到物理页上，内核只是分配了虚拟地址空间，并且建立了磁盘文件和虚拟地址空间的映射关系，当进程在访问这段地址时（读取文件file的内容或者写内容到文件），若虚拟内存对应的page没有在物理内存中缓存，则产生"缺页"，由内核的缺页异常处理程序处理，将文件对应内容，以页为单位(4096BYtes)加载到物理内存，注意是只加载缺页，但也会受操作系统一些调度策略影响，加载的比所需的多，这里就不展开了。(PS: 再具体一些，进程在访问7f35eea8d000这个进程虚拟地址时，MMU通过查找页表，发现对应内容未缓存在物理内存中，则产生"缺页")



7.在这里可以引申出 分别通过 mmap 和 read 函数从磁盘文件读取数据并发送数据至网络有何区别？

先来看`read`-`send`的数据流向图：



![image-18](https://i.postimg.cc/fbzmhjKN/18.png)



总结一下上面的流程：

- 进程 A 发出read 请求，陷入到内核，先创建内核缓冲区，通过read函数的参数 fd 找到磁盘的文件A，然后通过DMA将文件A的数据拷贝至物理内存(当然物理内存要提前分配好)
- 接着在内核页表增加内核虚拟地址到物理地址的映射记录。
- CPU 拷贝物理内存块1的数据至物理内存块2中，并建立用户buf虚拟地址和物理内存块2的映射关系
- 进程A发出Send请求将物理内存2存储的数据拷贝至物理内存块3中
- 最后一步通过DMA将数据拷贝至网卡发送到网络中





再来看下`mmap` -`send`的数据流向图：



![image-19](https://i.postimg.cc/7LK7PGsT/19.png)



总结一下上面的流程：

- 进程 A 发出 mmap 系统调用，陷入内核态并建立内核缓冲区，当用户要读取用户态buf的数据时，会发生缺页中断，进入到第二步。
- 当发生缺页中断的时候，会引发DMA将文件A的数据拷贝至物理内存块1中，然后建立内核缓冲区和物理内存块1的映射关系。
- 等到mmap返回至用户态的时候，此时，进程用户缓冲区已经和物理内存块1已经建立好映射关系，这样通过buf就可以找到物理内存块1中的数据了。
- 接着，当进程A发出 Send 请求的时候，cpu 会将内核缓冲区的数据拷贝至socket缓冲区中(其实真正拷贝到了物理内存块2中)
- 最后，通过DMA拷贝物理内存块2中的数据至网卡中，从而将数据发送至网络中。



**其实，mmap和read相比较的话，优势在于以下几个方面：**

- 第一个就是物理内存的节约，由上面的2个图来对比的话，mmap只用了一块物理内存来存储数据，而read采用了2块
- 少了一次数据拷贝的操作，read需要2次数据的拷贝，第一次拷贝是将磁盘文件拷贝至物理内存块1中，第二次是将物理内存块2的数据拷贝至用户态buf所映射的物理内存块2中。而mmap只需要拷贝一次，即：将磁盘文件拷贝至物理内存块1中。

​                                                                                        
